# rag_core.py
import sqlite3
import numpy as np
import faiss
from sentence_transformers import SentenceTransformer
from openai import OpenAI

# === è¨­å®š ===
DB_PATH = "oca_data.db"
MODEL_NAME = "all-MiniLM-L6-v2"
OPENAI_API_KEY = "ã‚ãªãŸã®OpenAI APIã‚­ãƒ¼"

client = OpenAI(api_key=OPENAI_API_KEY)
model = SentenceTransformer(MODEL_NAME)

# === ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ ===
def load_articles():
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    cursor.execute("SELECT id, title, text, category, subcategory FROM articles")
    data = cursor.fetchall()
    conn.close()
    return data

articles = load_articles()
texts = [a[2] for a in articles]
meta = [{"id": a[0], "title": a[1], "category": a[3], "subcategory": a[4]} for a in articles]

# === ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰ ===
print("ğŸ” ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ä¸­...")
embeddings = model.encode(texts, show_progress_bar=True)
dimension = embeddings.shape[1]
index = faiss.IndexFlatL2(dimension)
index.add(np.array(embeddings))
print("âœ… ãƒ™ã‚¯ãƒˆãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆå®Œäº†ï¼")

# === é¡ä¼¼æ¤œç´¢ ===
def search_similar_articles(query, top_k=3):
    q_vec = model.encode([query])
    D, I = index.search(np.array(q_vec), top_k)
    results = [texts[i] for i in I[0]]
    return results

# === å›ç­”ç”Ÿæˆ ===
def generate_answer(query):
    related = search_similar_articles(query)
    context = "\n\n".join(related)
    prompt = f"""
ã‚ãªãŸã¯å­¦æ ¡æ¡ˆå†…AIã§ã™ã€‚ä»¥ä¸‹ã®æƒ…å ±ã‚’ã‚‚ã¨ã«ã€è³ªå•ã«ç°¡æ½”ã§è‡ªç„¶ãªæ—¥æœ¬èªã§ç­”ãˆã¦ãã ã•ã„ã€‚
æƒ…å ±ãŒä¸ååˆ†ãªå ´åˆã¯ã€Œä¸æ˜ã§ã™ã€ã¨è¿°ã¹ã¦ãã ã•ã„ã€‚

---æƒ…å ±---
{context}

---è³ªå•---
{query}
"""

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message.content